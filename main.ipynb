{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade torch\n",
    "# !pip install transformers\n",
    "# !pip install easydict\n",
    "# !pip install colab-ssh --upgrade\n",
    "# !pip install openpyxl\n",
    "\n",
    "# from colab_ssh import launch_ssh_cloudflared, init_git_cloudflared\n",
    "# launch_ssh_cloudflared(password='0000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "# # mount Google Drive\n",
    "# drive.mount('/content/drive', force_remount=True)\n",
    "# GDRIVE_HOME = '/content/drive/MyDrive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment Option\n",
    "from easydict import EasyDict\n",
    "import torch\n",
    "\n",
    "opt = EasyDict()\n",
    "opt.dataset_series = 'sentihood' # SemEval-16, sentihood\n",
    "opt.dataset_domain = 'laptop' # restaurant / laptop / anything if sentihood\n",
    "opt.subtask = 'sub1' # sub1: sentence, sub2: document(full review) only sub1\n",
    "opt.task = 'category' # category, term\n",
    "opt.num_classes = 3 # negative, positive, neutral, (+ conflict)\n",
    "opt.max_length = 200\n",
    "opt.model_name = 'bert_attscore'\n",
    "# model_name: {bert_base, bert_attscore, bert_attscore_rnn, bert_attscore_bi_rnn, bert_attscore_rnn_add_asp,\n",
    "#    bert_attscore_rnn_add_sep1, bert_attscore_rnn_add_sep_both, bert_attscore_forcls_rnn}\n",
    "opt.pos = False # not use\n",
    "opt.lastid = False # not use\n",
    "opt.top_k = 3 # how many top-k attention score words to use\n",
    "opt.valset_ratio = 0.2\n",
    "opt.batch_size = 16\n",
    "opt.num_layers = 6 # only use bert_intermediate. how many intermediate layers to use?\n",
    "opt.num_epochs = 12\n",
    "opt.runs = 5\n",
    "opt.seed = 42\n",
    "opt.log_step = 100\n",
    "opt.patience = 5\n",
    "opt.device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "\n",
    "print(opt.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4,
     7
    ]
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "# research_root = os.path.join(GDRIVE_HOME, 'research')\n",
    "# sys.path.append(research_root)\n",
    "\n",
    "if opt.dataset_series == 'SemEval-16':\n",
    "    path = 'dataset/{}/semeval16_{}_{}.csv'.format(opt.dataset_series, opt.subtask, opt.dataset_domain)\n",
    "    path_test = 'dataset/{}/semeval16_{}_{}_test.csv'.format(opt.dataset_series, opt.subtask, opt.dataset_domain)\n",
    "elif opt.dataset_series == 'sentihood':\n",
    "    path = 'dataset/{}/sentihood_train.csv'.format(opt.dataset_series)\n",
    "    path_test = 'dataset/{}/sentihood_test.csv'.format(opt.dataset_series)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(path)\n",
    "df_test = pd.read_csv(path_test)\n",
    "\n",
    "print('length of train set: {:,}'.format(len(df_train)))\n",
    "print('length of test set: {:,}'.format(len(df_test)))\n",
    "\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'attscore' in opt.model_name: # remove some noise('., -, _')\n",
    "    from data_utils import clean_sentence, preprocess\n",
    "    df_train = clean_sentence(df=df_train, clean_func=preprocess)\n",
    "    df_test = clean_sentence(df=df_test, clean_func=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import Category_Classification_Dataset as Dataset\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "trainset = Dataset(df=df_train, tokenizer=tokenizer, opt=opt, pos_encoding=False)\n",
    "testset = Dataset(df=df_test, tokenizer=tokenizer, opt=opt, pos_encoding=False)\n",
    "\n",
    "# print(trainset.get_sample(423))\n",
    "# print('-'*30)\n",
    "# print(trainset[423])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import custom_random_split as rs\n",
    "\n",
    "train_set, val_set, test_set = rs(dataset=trainset, testset=testset,\n",
    "                                  val_ratio=opt.valset_ratio, random_seed=opt.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=opt.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_set, batch_size=opt.batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=opt.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use top-k attention words + some tokens + pooling\n",
    "\n",
    "- top-k: 3, 4\n",
    "- additional tokens: [SEP_1], [SEP_2], both [SEP], [CLS], pair words(aspect words)\n",
    "- pooling: 'mean' or 'bi-gru'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.bert_intermediate import *\n",
    "#from models.bert_pos import *\n",
    "from models.bert_attscores import *\n",
    "\n",
    "if opt.model_name == 'bert_base':\n",
    "    model = Bert_Base(opt.num_classes)\n",
    "elif opt.model_name == 'bert_attscore':\n",
    "    model = Bert_AttScore(opt=opt, embed_dim=768, fc_hid_dim=128, top_k=opt.top_k, att_head='all', att_pooling='mean')\n",
    "elif opt.model_name == 'bert_attscore_rnn':\n",
    "    model = Bert_AttScore_RNN(opt=opt, embed_dim=768, rnn_hid_dim=256, fc_hid_dim=128, bidirectional=False,\n",
    "                              top_k=opt.top_k, att_head='all', att_pooling='gru')\n",
    "elif opt.model_name == 'bert_attscore_bi_rnn':\n",
    "    model = Bert_AttScore_RNN(opt=opt, embed_dim=768, rnn_hid_dim=256, fc_hid_dim=128, bidirectional=True,\n",
    "                              top_k=opt.top_k, att_head='all', att_pooling='gru')\n",
    "elif opt.model_name == 'bert_attscore_rnn_add_sep1':\n",
    "    model = Bert_AttScore_RNN_add(opt=opt, embed_dim=768, rnn_hid_dim=256, fc_hid_dim=128, bidirectional=True,\n",
    "                                 top_k=opt.top_k, att_head='all', additional_token='sep1', att_pooling='gru')\n",
    "elif opt.model_name == 'bert_attscore_rnn_add_sep2':\n",
    "    model = Bert_AttScore_RNN_add(opt=opt, embed_dim=768, rnn_hid_dim=256, fc_hid_dim=128, bidirectional=True,\n",
    "                                 top_k=opt.top_k, att_head='all', additional_token='sep2', att_pooling='gru')\n",
    "elif opt.model_name == 'bert_attscore_rnn_add_sep_both':\n",
    "    model = Bert_AttScore_RNN_add(opt=opt, embed_dim=768, rnn_hid_dim=256, fc_hid_dim=128, bidirectional=True,\n",
    "                                 top_k=opt.top_k, att_head='all', additional_token='sep_both', att_pooling='gru')\n",
    "elif opt.model_name == 'bert_attscore_rnn_add_asp':\n",
    "    model = Bert_AttScore_RNN_add(opt=opt, embed_dim=768, rnn_hid_dim=256, fc_hid_dim=128, bidirectional=True,\n",
    "                                 top_k=opt.top_k, att_head='all', additional_token='asp', att_pooling='gru')\n",
    "elif opt.model_name == 'bert_attscore_rnn_add_cls':\n",
    "    model = Bert_AttScore_RNN_add(opt=opt, embed_dim=768, rnn_hid_dim=256, fc_hid_dim=128, bidirectional=True,\n",
    "                                 top_k=opt.top_k, att_head='all', additional_token='cls', att_pooling='gru')\n",
    "elif opt.model_name == 'bert_attscore_forcls_rnn':\n",
    "    model = Bert_AttScore_forCLS_RNN(opt=opt, embed_dim=768, rnn_hid_dim=256, fc_hid_dim=128, bidirectional=True,\n",
    "                                 top_k=opt.top_k, att_head='all', att_pooling='gru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.parameters import get_parameters\n",
    "total, params = get_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from custom_trainer import *\n",
    "\n",
    "optimizer = optim.AdamW(params, lr=2e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.8) # can't use for multiple runs\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "result_dict, best_path = runs(trainer=trainer, train_loader=train_loader, val_loader=val_loader, test_loader=test_loader,\n",
    "                             model=model, criterion=criterion, optimizer=optimizer, scheduler=False, opt=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
